{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6188fcde",
      "metadata": {
        "id": "6188fcde"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm numpy scipy pandas torch torchvision einops wfdb scikit-learn datasets pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nC9sYJJeyPhU",
      "metadata": {
        "id": "nC9sYJJeyPhU"
      },
      "outputs": [],
      "source": [
        "# !wandb login\n",
        "# from pytorch_lightning.loggers import WandbLogger\n",
        "# from pytorch_lightning import Trainer\n",
        "\n",
        "# wandb_logger = WandbLogger(log_model=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7e1002",
      "metadata": {
        "id": "ae7e1002"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorch_lightning.callbacks import RichProgressBar\n",
        "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Wavelet memory sequence modeling layer \"\"\"\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pywt\n",
        "\n",
        "\n",
        "class MultiresLayer(nn.Module):\n",
        "    def __init__(self, d_model, kernel_size=None, depth=None, wavelet_init=None, tree_select=\"fading\",\n",
        "                 seq_len=None, dropout=0., memory_size=None, indep_res_init=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.kernel_size = kernel_size\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.tree_select = tree_select\n",
        "        if depth is not None:\n",
        "            self.depth = depth\n",
        "        elif seq_len is not None:\n",
        "            self.depth = self.max_depth(seq_len)\n",
        "        else:\n",
        "            raise ValueError(\"Either depth or seq_len must be provided.\")\n",
        "        print(\"depth:\", self.depth)\n",
        "\n",
        "        if tree_select == \"fading\":\n",
        "            self.m = self.depth + 1\n",
        "        elif memory_size is not None:\n",
        "            self.m = memory_size\n",
        "        else:\n",
        "            raise ValueError(\"memory_size must be provided when tree_select != 'fading'\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if wavelet_init is not None:\n",
        "                self.wavelet = pywt.Wavelet(wavelet_init)\n",
        "                h0 = torch.tensor(self.wavelet.dec_lo[::-1], dtype=torch.float32)\n",
        "                h1 = torch.tensor(self.wavelet.dec_hi[::-1], dtype=torch.float32)\n",
        "                self.h0 = nn.Parameter(torch.tile(h0[None, None, :], [d_model, 1, 1]))\n",
        "                self.h1 = nn.Parameter(torch.tile(h1[None, None, :], [d_model, 1, 1]))\n",
        "            elif kernel_size is not None:\n",
        "                self.h0 = nn.Parameter(\n",
        "                    torch.empty(d_model, 1, kernel_size).uniform_(-1., 1.) *\n",
        "                    math.sqrt(2.0 / (kernel_size * 2))\n",
        "                )\n",
        "                self.h1 = nn.Parameter(\n",
        "                    torch.empty(d_model, 1, kernel_size).uniform_(-1., 1.) *\n",
        "                    math.sqrt(2.0 / (kernel_size * 2))\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"kernel_size must be specified for non-wavelet initialization.\")\n",
        "\n",
        "            w_init = torch.empty(\n",
        "                d_model, self.m + 1).uniform_(-1., 1.) * math.sqrt(2.0 / (2*self.m + 2))\n",
        "            if indep_res_init:\n",
        "                w_init[:, -1] = torch.empty(d_model).uniform_(-1., 1.)\n",
        "            self.w = nn.Parameter(w_init)\n",
        "\n",
        "        self.activation = nn.GELU()\n",
        "        dropout_fn = nn.Dropout1d\n",
        "        self.dropout = dropout_fn(dropout) if dropout > 0. else nn.Identity()\n",
        "\n",
        "    def max_depth(self, L):\n",
        "        depth = math.ceil(math.log2((L - 1) / (self.kernel_size - 1) + 1))\n",
        "        return depth\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.tree_select == \"fading\":\n",
        "            y = forward_fading(x, self.h0, self.h1, self.w, self.depth, self.kernel_size)\n",
        "        elif self.tree_select == \"uniform\":\n",
        "            y = forward_uniform(x, self.h0, self.h1, self.w, self.depth, self.kernel_size, self.m)\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "        y = self.dropout(self.activation(y))\n",
        "        return y\n",
        "\n",
        "\n",
        "def forward_fading(x, h0, h1, w, depth, kernel_size):\n",
        "    res_lo = x\n",
        "    y = 0.\n",
        "    dilation = 1\n",
        "    for i in range(depth, 0, -1):\n",
        "        padding = dilation * (kernel_size - 1)\n",
        "        res_lo_pad = torch.nn.functional.pad(res_lo, (padding, 0), \"constant\", 0)\n",
        "        res_hi = torch.nn.functional.conv1d(res_lo_pad, h1, dilation=dilation, groups=x.shape[1])\n",
        "        res_lo = torch.nn.functional.conv1d(res_lo_pad, h0, dilation=dilation, groups=x.shape[1])\n",
        "        y += w[:, i:i + 1] * res_hi\n",
        "        dilation *= 2\n",
        "\n",
        "    y += w[:, :1] * res_lo\n",
        "    y += x * w[:, -1:]\n",
        "    return y\n",
        "\n",
        "\n",
        "def forward_uniform(x, h0, h1, w, depth, kernel_size, memory_size):\n",
        "    # x: [bs, d_model, L]\n",
        "    coeff_lst = []\n",
        "    dilation_lst = [1]\n",
        "    dilation = 1\n",
        "    res_lo = x\n",
        "    for _ in range(depth):\n",
        "        padding = dilation * (kernel_size - 1)\n",
        "        res_lo_pad = torch.nn.functional.pad(res_lo, (padding, 0), \"constant\", 0)\n",
        "        res_hi = torch.nn.functional.conv1d(res_lo_pad, h1, dilation=dilation, groups=x.shape[1])\n",
        "        res_lo = torch.nn.functional.conv1d(res_lo_pad, h0, dilation=dilation, groups=x.shape[1])\n",
        "        coeff_lst.append(res_hi)\n",
        "        dilation *= 2\n",
        "        dilation_lst.append(dilation)\n",
        "    coeff_lst.append(res_lo)\n",
        "    coeff_lst = coeff_lst[::-1]\n",
        "    dilation_lst = dilation_lst[::-1]\n",
        "\n",
        "    # y: [bs, d_model, L]\n",
        "    y = uniform_tree_select(coeff_lst, dilation_lst, w, kernel_size, memory_size)\n",
        "    y = y + x * w[:, -1:]\n",
        "    return y\n",
        "\n",
        "\n",
        "def uniform_tree_select(coeff_lst, dilation_lst, w, kernel_size, memory_size):\n",
        "    latent_dim = 1\n",
        "    y_lst = [coeff_lst[0] * w[:, 0, None]]\n",
        "    layer_dim = 1\n",
        "    dilation_lst[0] = 1\n",
        "    for l, coeff_l in enumerate(coeff_lst[1:]):\n",
        "        if latent_dim + layer_dim > memory_size:\n",
        "            layer_dim = memory_size - latent_dim\n",
        "        # layer_w: [d, layer_dim]\n",
        "        layer_w = w[:, latent_dim:latent_dim + layer_dim]\n",
        "        # coeff_l_pad: [bs, d, L + left_pad]\n",
        "        left_pad = (layer_dim - 1) * dilation_lst[l]\n",
        "        coeff_l_pad = torch.nn.functional.pad(coeff_l, (left_pad, 0), \"constant\", 0)\n",
        "        # y: [bs, d, L]\n",
        "        y = torch.nn.functional.conv1d(\n",
        "            coeff_l_pad,\n",
        "            torch.flip(layer_w[:, None, :], (-1,)),\n",
        "            dilation=dilation_lst[l],\n",
        "            groups=coeff_l.shape[1],\n",
        "        )\n",
        "        y_lst.append(y)\n",
        "        latent_dim += layer_dim\n",
        "        if latent_dim >= memory_size:\n",
        "            break\n",
        "        layer_dim = 2 * (layer_dim - 1) + kernel_size\n",
        "    return sum(y_lst)"
      ],
      "metadata": {
        "id": "5OLvK8yJEtp4"
      },
      "id": "5OLvK8yJEtp4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributed import init_process_group\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "\n",
        "def apply_norm(x, norm, batch_norm=False):\n",
        "    if batch_norm:\n",
        "        return norm(x)\n",
        "    else:\n",
        "        return norm(x.transpose(-1, -2)).transpose(-1, -2)\n",
        "\n",
        "\n",
        "def ddp_setup(rank, world_size, port):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        rank: Unique identifier of each process\n",
        "        world_size: Total number of processes\n",
        "    \"\"\"\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    os.environ[\"MASTER_PORT\"] = port\n",
        "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "\n",
        "\n",
        "def split_train_val(train, val_split):\n",
        "    train_len = int(len(train) * (1.0-val_split))\n",
        "    train, val = torch.utils.data.random_split(\n",
        "        train,\n",
        "        (train_len, len(train) - train_len),\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "    return train, val\n",
        "\n",
        "\n",
        "class DistributedSamplerNoDuplicate(torch.utils.data.DistributedSampler):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if not self.drop_last and len(self.dataset) % self.num_replicas != 0:\n",
        "            # some ranks may have less samples, that's fine\n",
        "            if self.rank >= len(self.dataset) % self.num_replicas:\n",
        "                self.num_samples -= 1\n",
        "            self.total_size = len(self.dataset)\n",
        "\n",
        "\n",
        "def log_sum_exp(x):\n",
        "    \"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"\n",
        "    # TF ordering\n",
        "    axis  = len(x.size()) - 1\n",
        "    m, _  = torch.max(x, dim=axis)\n",
        "    m2, _ = torch.max(x, dim=axis, keepdim=True)\n",
        "    return m + torch.log(torch.sum(torch.exp(x - m2), dim=axis))\n",
        "\n",
        "\n",
        "def log_prob_from_logits(x):\n",
        "    \"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"\n",
        "    # TF ordering\n",
        "    axis = len(x.size()) - 1\n",
        "    m, _ = torch.max(x, dim=axis, keepdim=True)\n",
        "    return x - m - torch.log(torch.sum(torch.exp(x - m), dim=axis, keepdim=True))\n",
        "\n",
        "\n",
        "# https://github.com/pclucas14/pixel-cnn-pp/blob/master/utils.py\n",
        "def discretized_mix_logistic_loss(x, l):\n",
        "    \"\"\" log-likelihood for mixture of discretized logistics, assumes the data has been rescaled to [-1,1] interval \"\"\"\n",
        "    # Pytorch ordering\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    l = l.permute(0, 2, 3, 1)\n",
        "    xs = [int(y) for y in x.size()]\n",
        "    ls = [int(y) for y in l.size()]\n",
        "\n",
        "    # here and below: unpacking the params of the mixture of logistics\n",
        "    nr_mix = int(ls[-1] / 10)\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3]) # 3 for mean, scale, coef\n",
        "    means = l[:, :, :, :, :nr_mix]\n",
        "    # log_scales = torch.max(l[:, :, :, :, nr_mix:2 * nr_mix], -7.)\n",
        "    log_scales = torch.clamp(l[:, :, :, :, nr_mix:2 * nr_mix], min=-7.)\n",
        "\n",
        "    coeffs = torch.tanh(l[:, :, :, :, 2 * nr_mix:3 * nr_mix])\n",
        "    # here and below: getting the means and adjusting them based on preceding\n",
        "    # sub-pixels\n",
        "    x = x.contiguous()\n",
        "    x = x.unsqueeze(-1) + torch.zeros(xs + [nr_mix], device=x.device)\n",
        "    m2 = (means[:, :, :, 1, :] + coeffs[:, :, :, 0, :]\n",
        "                * x[:, :, :, 0, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
        "\n",
        "    m3 = (means[:, :, :, 2, :] + coeffs[:, :, :, 1, :] * x[:, :, :, 0, :] +\n",
        "                coeffs[:, :, :, 2, :] * x[:, :, :, 1, :]).view(xs[0], xs[1], xs[2], 1, nr_mix)\n",
        "\n",
        "    means = torch.cat((means[:, :, :, 0, :].unsqueeze(3), m2, m3), dim=3)\n",
        "    centered_x = x - means\n",
        "    inv_stdv = torch.exp(-log_scales)\n",
        "    plus_in = inv_stdv * (centered_x + 1. / 255.)\n",
        "    cdf_plus = torch.sigmoid(plus_in)\n",
        "    min_in = inv_stdv * (centered_x - 1. / 255.)\n",
        "    cdf_min = torch.sigmoid(min_in)\n",
        "    # log probability for edge case of 0 (before scaling)\n",
        "    log_cdf_plus = plus_in - F.softplus(plus_in)\n",
        "    # log probability for edge case of 255 (before scaling)\n",
        "    log_one_minus_cdf_min = -F.softplus(min_in)\n",
        "    cdf_delta = cdf_plus - cdf_min  # probability for all other cases\n",
        "    mid_in = inv_stdv * centered_x\n",
        "    # log probability in the center of the bin, to be used in extreme cases\n",
        "    # (not actually used in our code)\n",
        "    log_pdf_mid = mid_in - log_scales - 2. * F.softplus(mid_in)\n",
        "\n",
        "    # now select the right output: left edge case, right edge case, normal\n",
        "    # case, extremely low prob case (doesn't actually happen for us)\n",
        "\n",
        "    # this is what we are really doing, but using the robust version below for extreme cases in other applications and to avoid NaN issue with tf.select()\n",
        "    # log_probs = tf.select(x < -0.999, log_cdf_plus, tf.select(x > 0.999, log_one_minus_cdf_min, tf.log(cdf_delta)))\n",
        "\n",
        "    # robust version, that still works if probabilities are below 1e-5 (which never happens in our code)\n",
        "    # tensorflow backpropagates through tf.select() by multiplying with zero instead of selecting: this requires use to use some ugly tricks to avoid potential NaNs\n",
        "    # the 1e-12 in tf.maximum(cdf_delta, 1e-12) is never actually used as output, it's purely there to get around the tf.select() gradient issue\n",
        "    # if the probability on a sub-pixel is below 1e-5, we use an approximation\n",
        "    # based on the assumption that the log-density is constant in the bin of\n",
        "    # the observed sub-pixel value\n",
        "\n",
        "    inner_inner_cond = (cdf_delta > 1e-5).float()\n",
        "    inner_inner_out  = inner_inner_cond * torch.log(torch.clamp(cdf_delta, min=1e-12)) + (1. - inner_inner_cond) * (log_pdf_mid - np.log(127.5))\n",
        "    inner_cond       = (x > 0.999).float()\n",
        "    inner_out        = inner_cond * log_one_minus_cdf_min + (1. - inner_cond) * inner_inner_out\n",
        "    cond             = (x < -0.999).float()\n",
        "    log_probs        = cond * log_cdf_plus + (1. - cond) * inner_out\n",
        "    log_probs        = torch.sum(log_probs, dim=3) + log_prob_from_logits(logit_probs)\n",
        "\n",
        "    return -torch.sum(log_sum_exp(log_probs))\n",
        "\n",
        "\n",
        "def sample_from_discretized_mix_logistic(l, nr_mix):\n",
        "    # Pytorch ordering\n",
        "    l = l.permute(0, 2, 3, 1)\n",
        "    ls = [int(y) for y in l.size()]\n",
        "    xs = ls[:-1] + [3]\n",
        "\n",
        "    # unpack parameters\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 3])\n",
        "    # sample mixture indicator from softmax\n",
        "    temp = torch.empty(logit_probs.size(), device=l.device)\n",
        "    temp.uniform_(1e-5, 1. - 1e-5)\n",
        "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
        "    _, argmax = temp.max(dim=3)\n",
        "\n",
        "    one_hot = to_one_hot(argmax, nr_mix)\n",
        "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
        "    # select logistic parameters\n",
        "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4)\n",
        "    log_scales = torch.clamp(torch.sum(\n",
        "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
        "    coeffs = torch.sum(torch.tanh(\n",
        "        l[:, :, :, :, 2 * nr_mix:3 * nr_mix]) * sel, dim=4)\n",
        "    # sample from logistic & clip to interval\n",
        "    # we don't actually round to the nearest 8bit value when sampling\n",
        "    u = torch.empty(means.size(), device=means.device)\n",
        "    u.uniform_(1e-5, 1. - 1e-5)\n",
        "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
        "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
        "    x1 = torch.clamp(torch.clamp(\n",
        "       x[:, :, :, 1] + coeffs[:, :, :, 0] * x0, min=-1.), max=1.)\n",
        "    x2 = torch.clamp(torch.clamp(\n",
        "       x[:, :, :, 2] + coeffs[:, :, :, 1] * x0 + coeffs[:, :, :, 2] * x1, min=-1.), max=1.)\n",
        "\n",
        "    out = torch.cat([x0.view(xs[:-1] + [1]), x1.view(xs[:-1] + [1]), x2.view(xs[:-1] + [1])], dim=3)\n",
        "    # put back in Pytorch ordering\n",
        "    out = out.permute(0, 3, 1, 2)\n",
        "    return out\n",
        "\n",
        "\n",
        "def to_one_hot(tensor, n, fill_with=1.):\n",
        "    # we perform one hot encore with respect to the last axis\n",
        "    one_hot = torch.FloatTensor(tensor.size() + (n,), device=tensor.device).zero_()\n",
        "    one_hot.scatter_(len(tensor.size()), tensor.unsqueeze(-1), fill_with)\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "def sample_from_discretized_mix_logistic_1d(l, nr_mix):\n",
        "    # Pytorch ordering\n",
        "    l = l.permute(0, 2, 3, 1)\n",
        "    ls = [int(y) for y in l.size()]\n",
        "    xs = ls[:-1] + [1] #[3]\n",
        "\n",
        "    # unpack parameters\n",
        "    logit_probs = l[:, :, :, :nr_mix]\n",
        "    l = l[:, :, :, nr_mix:].contiguous().view(xs + [nr_mix * 2]) # for mean, scale\n",
        "\n",
        "    # sample mixture indicator from softmax\n",
        "    temp = torch.FloatTensor(logit_probs.size(), device=l.device)\n",
        "    temp.uniform_(1e-5, 1. - 1e-5)\n",
        "    temp = logit_probs.data - torch.log(- torch.log(temp))\n",
        "    _, argmax = temp.max(dim=3)\n",
        "\n",
        "    one_hot = to_one_hot(argmax, nr_mix)\n",
        "    sel = one_hot.view(xs[:-1] + [1, nr_mix])\n",
        "    # select logistic parameters\n",
        "    means = torch.sum(l[:, :, :, :, :nr_mix] * sel, dim=4)\n",
        "    log_scales = torch.clamp(torch.sum(\n",
        "        l[:, :, :, :, nr_mix:2 * nr_mix] * sel, dim=4), min=-7.)\n",
        "    u = torch.FloatTensor(means.size(), device=l.device)\n",
        "    u.uniform_(1e-5, 1. - 1e-5)\n",
        "    x = means + torch.exp(log_scales) * (torch.log(u) - torch.log(1. - u))\n",
        "    x0 = torch.clamp(torch.clamp(x[:, :, :, 0], min=-1.), max=1.)\n",
        "    out = x0.unsqueeze(1)\n",
        "    return out\n",
        "\n",
        "\n",
        "def setup_logger(name, src, result_path, filename=\"log\"):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    log_path = os.path.join(result_path, filename)\n",
        "    makedirs(log_path)\n",
        "    info_file_handler = logging.FileHandler(log_path)\n",
        "    info_file_handler.setLevel(logging.INFO)\n",
        "    logger.addHandler(info_file_handler)\n",
        "    logger.info(src)\n",
        "    with open(src) as f:\n",
        "        logger.info(f.read())\n",
        "    return logger\n",
        "\n",
        "\n",
        "def makedirs(filename):\n",
        "    if not os.path.exists(os.path.dirname(filename)):\n",
        "        os.makedirs(os.path.dirname(filename))\n",
        "\n",
        "\n",
        "def ensure_path(path, other):\n",
        "    if os.path.exists(path):\n",
        "        return path\n",
        "    return other\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    # for p in model.parameters():\n",
        "    #     if p.requires_grad:\n",
        "    #         print(p.shape)\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "class DotDict(dict):\n",
        "    \"\"\"dot.notation access to dictionary attributes\n",
        "    From https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary\n",
        "    Note that there are issues with updating values of nested DotDicts\n",
        "    \"\"\"\n",
        "\n",
        "    def __getattr__(*args):\n",
        "        # Allow nested dicts\n",
        "        val = dict.get(*args)\n",
        "        return DotDict(val) if type(val) is dict else val\n",
        "\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "    __dir__ = dict.keys\n",
        "\n",
        "\n",
        "class DummyWandb:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "        self.config = {}\n",
        "        self.name = \"\"\n",
        "        self.id = \"\"\n",
        "        self.path = \"\"\n",
        "        self.dir = \"./\"\n",
        "\n",
        "    @staticmethod\n",
        "    def init(*args, **kwargs):\n",
        "        return DummyWandb(*args, **kwargs)\n",
        "\n",
        "    def log(self, *args, **kwargs):\n",
        "        return\n",
        "\n",
        "    def watch(self, *args, **kwargs):\n",
        "        return\n",
        "\n",
        "    def finish(self, *args, **kwargs):\n",
        "        return\n",
        "\n",
        "    def save(self, *args, **kwargs):\n",
        "        return\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "    optimizer: Optimizer, num_warmup_steps: int, num_training_steps: int, num_cycles: float = 0.5, last_epoch: int = -1\n",
        "):\n",
        "    \"\"\" From: https://github.com/huggingface/transformers/blob/main/src/transformers/optimization.py,\n",
        "    This way we don't have dependency on the `transformers` package.\n",
        "\n",
        "    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "    initial lr set in the optimizer.\n",
        "\n",
        "    Args:\n",
        "        optimizer ([`~torch.optim.Optimizer`]):\n",
        "            The optimizer for which to schedule the learning rate.\n",
        "        num_warmup_steps (`int`):\n",
        "            The number of steps for the warmup phase.\n",
        "        num_training_steps (`int`):\n",
        "            The total number of training steps.\n",
        "        num_cycles (`float`, *optional*, defaults to 0.5):\n",
        "            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "            following a half-cosine).\n",
        "        last_epoch (`int`, *optional*, defaults to -1):\n",
        "            The index of the last epoch when resuming training.\n",
        "\n",
        "    Return:\n",
        "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "    \"\"\"\n",
        "\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
        "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n",
        "\n",
        "    return LambdaLR(optimizer, lr_lambda, last_epoch)"
      ],
      "metadata": {
        "id": "E5l5zwQeFGa_"
      },
      "id": "E5l5zwQeFGa_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679bff7b",
      "metadata": {
        "id": "679bff7b"
      },
      "outputs": [],
      "source": [
        "tiny_model = {\n",
        "    \"d_model\": 256,\n",
        "    \"n_layer\": 6,\n",
        "    \"vocab_size\": 16,\n",
        "    \"ssm_cfg\": {},\n",
        "    \"rms_norm\": True,\n",
        "    \"residual_in_fp32\": True,\n",
        "    \"fused_add_norm\": True,\n",
        "    \"pad_vocab_size_multiple\": 8\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export LC_ALL=\"en_US.UTF-8\"\n",
        "!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n",
        "!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n",
        "!ldconfig /usr/lib64-nvidia"
      ],
      "metadata": {
        "id": "p3hWHoHEQTsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71233659-09c6-41a0-ebd4-f6ab38a2944e"
      },
      "id": "p3hWHoHEQTsG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wvzGnQsWqdh2",
      "metadata": {
        "id": "wvzGnQsWqdh2"
      },
      "outputs": [],
      "source": [
        "def tokenize(dataset: Dataset) -> Tuple[Tensor, Dict]:\n",
        "    dictionary = Dictionary()\n",
        "\n",
        "\n",
        "    for sequence in dataset['train']['sequence']:\n",
        "            words = list(sequence) + [\"<eos>\"]\n",
        "            for word in words:\n",
        "                dictionary.add_word(word)\n",
        "    idss: List[Tensor] = []\n",
        "    # Tokenize file content\n",
        "    for sequence in dataset['train']['sequence']:\n",
        "            words = list(sequence) + [\"<eos>\"]\n",
        "            ids: List[int] = []\n",
        "            for word in words:\n",
        "                ids.append(dictionary.word2idx[word])\n",
        "            idss.append(torch.tensor(ids).type(torch.int64))\n",
        "    return torch.cat(idss), dictionary\n",
        "\n",
        "class Dictionary:\n",
        "    def __init__(self) -> None:\n",
        "        self.word2idx: Dict[str, int] = {}\n",
        "        self.idx2word: List[str] = []\n",
        "\n",
        "    def add_word(self, word: str) -> int:\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.idx2word)\n",
        "\n",
        "class VirusDataset(Dataset):\n",
        "    \"\"\"Virus dataset - This will need to be redone\"\"\"\n",
        "\n",
        "    def __init__(self, dataset_name:str,  block_size: int = 64) -> None:\n",
        "        super().__init__()\n",
        "        self.dataset = load_dataset(dataset_name)\n",
        "        self.data, self.dictionary = tokenize(self.dataset)\n",
        "        self.block_size = block_size\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self) -> int:\n",
        "        return len(self.dictionary)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data) // self.block_size - 1\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Tensor, Tensor]:\n",
        "        start = index * self.block_size\n",
        "        end = start + self.block_size\n",
        "        inputs = self.data[start:end]\n",
        "        return inputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tsF-T5ggnuTI",
      "metadata": {
        "id": "tsF-T5ggnuTI"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = MultiresLayer(**)\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        input = batch\n",
        "        lm_logits = self.model(input).logits\n",
        "        labels = input.to(lm_logits.device)\n",
        "        shift_logits = lm_logits[:, :-1, :].contiguous()\n",
        "        labels = labels[:, 1:].contiguous()\n",
        "\n",
        "        loss_fct = torch.nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.1)\n",
        "\n",
        "pl.seed_everything(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qLzg01QqOGz8",
      "metadata": {
        "id": "qLzg01QqOGz8"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "dataset  = VirusDataset(dataset_name= 'Hack90/chikungunya')\n",
        "train_dataloader = DataLoader(dataset, batch_size=512, num_workers=7)\n",
        "\n",
        "# Model\n",
        "model = LanguageModel()\n",
        "\n",
        "# Trainer\n",
        "trainer = pl.Trainer(accelerator=\"cuda\", devices=1, max_epochs=1 )#logger=wandb_logger)\n",
        "trainer.fit(model, train_dataloader)\n",
        "trainer.print(f\"Memory used: {torch.cuda.max_memory_allocated() / 1e9:.02f} GB\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}